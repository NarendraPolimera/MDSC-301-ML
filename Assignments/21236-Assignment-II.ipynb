{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Questions-I from MDSC-301(P)\n",
    "\n",
    "----------------------------------------------------------------\n",
    "Author: P. Narendra Kumar Reddy\n",
    "\n",
    "Date: September 5, 2022\n",
    "\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Which Linear Regression training algorithm can you use if you have\n",
    "a training set with millions of features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. \n",
    "* Gradient Descent and it's variants like batch gradient descent and stochastic gradient descent can be used as they won't load the entire data to perform gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Suppose the features in your training set have very different scales.\n",
    "Which algorithms might suffer from this, and how? What can you\n",
    "do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2. \n",
    "* Gradient Descent suffers, as model takes lot of time to reach global minimum.\n",
    "* Feature scaling has to be done by using techniques like \"Normalization, Standardization, Scaling to unit length, etc\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.  Suppose you use Batch Gradient Descent and you plot the validation\n",
    "error at every epoch. If you notice that the validation error\n",
    "consistently goes up, what is likely going on? How can you fix this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3. \n",
    "* If the validation error alone consequently going up but training error is very less then it is over-fitting.\n",
    "* This can be fixed by using Regularization technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Is it a good idea to stop Mini-batch Gradient Descent immediately\n",
    "when the validation error goes up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A4.\n",
    "* No.\n",
    "* As it is mini- batch gradient descent there may be other batches in future iterations where higher validation error may not occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Suppose you are using Polynomial Regression. You plot the learning\n",
    "curves and you notice that there is a large gap between the training\n",
    "error and the validation error. What is happening? What are three\n",
    "ways to solve this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A5. \n",
    "* If the difference between training error and validation error is more then model is overfitting the data.\n",
    "* Three ways to solve overfitting are:\n",
    "1. Reguralization\n",
    "2. Cross Validation\n",
    "3. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Suppose you are using Ridge Regression and you notice that the\n",
    "training error and the validation error are almost equal and fairly\n",
    "high. Would you say that the model suffers from high bias or high\n",
    "variance? Should you increase the regularization hyperparameter $\\alpha$\n",
    "or reduce it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A6.\n",
    "* High bias\n",
    "* Reduce $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Why would you want to use:\n",
    "   - Ridge Regression instead of plain Linear Regression (i.e., without any regularization)?\n",
    "   - Lasso instead of Ridge Regression?\n",
    "   - Elastic Net instead of Lasso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A7. \n",
    "* Ridge Regression ensures the model doesn't overfit to the data by adding L2 regularization term.\n",
    "* Lasso Regression automatically does feature selection and outputs a sparse model.\n",
    "* Lasso performs unpredictably when the features are highly correlated and when the features are more than the number of training instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8.  Can you name four of the main challenges in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A8. \n",
    "1. Under Fitting and Over Fitting\n",
    "2. insufficient training data\n",
    "3. Lack of quality data\n",
    "4. Unwanted features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. If your model performs great on the training data but generalizes\n",
    "poorly to new instances, what is happening? Can you name three\n",
    "possible solutions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A9. \n",
    "* Over Fitting\n",
    "* Three possible solutions are:\n",
    "1. Feature Selection\n",
    "2. Train with more data\n",
    "3. Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. What is a test set, and why would you want to use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A10. \n",
    "* Test set is a small part (usually 20%) of the dataset, which won't be shown to the model during training.\n",
    "* So, after training we test the model on training data which is not seen by the model till now and meaasure accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11.  What is the purpose of a validation set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A11.\n",
    "* Validation set is a sample of data (usually 20%) used to test the model trained on training data and tune hyperparameters to improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. What are different loss functions? Exaplain their importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A12.\n",
    "* Mean Square Error(MSE) = ${\\sum_{i=1}^{n}\\frac{(y_{i} - \\hat{y}_{i})^2}{n}}$\n",
    "    - Predictions are penelized heavily as the errors are being squared but squaring makes gradients calculation easier.\n",
    "* Mean Absolute Error (MAE) = ${\\sum_{i=1}^{n}\\frac{|y_{i} - \\hat{y}_{i}|}{n}}$\n",
    "    - MAE is more robust in finding out outliers but complicated in calculating gradients.\n",
    "* Hinge Loss/Multi class SVM loss = ${\\sum_{j!=y_{i}} \\max(0,s_{j} - s{yi} + 1)}$\n",
    "    - It is used in classifiers like SVM for maximum-margin classification.\n",
    "* Cross Entropy/Negative Log Likelihood = $-{(y_{i}log(hat{y}_{i})+(1-y_{i})log(1-hat{y}_{i}))}$\n",
    "    - Used for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13. Explain the following:\n",
    "    - Gradient descent\n",
    "    - Mini-batch gradient descent\n",
    "    - Batch gradient, and\n",
    "    - Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A13.\n",
    "* Gradient descent: \n",
    "    - Gradient descent is an iterative first-order optimization techniwue used to find a local minimum/maximum of a convex function.\n",
    "    - It is used in machine learning and deep learning to minimize the loss/cost function.\n",
    "    - The next value is calculated by taking the current value and subtracting it with the product of learning rate $(\\lambda)$ and gradient at the current position.\n",
    "    - by repeting the above step it moves towards the minimum.\n",
    "\n",
    "* Batch Gradient Descent:\n",
    "    - Gradient descent is calculated in a single step in Batch Gradient Descent algoritnm.\n",
    "    - The average of all the training examples is taken and then use the mean gradient to update the parameter.\n",
    "\n",
    "* Stochastic gradient descent:\n",
    "    - SGD works well when dataset is huge.\n",
    "    - This takes just one example at a time in a single step.\n",
    "    - Overhead of SGD is, it is slow as it can't be vectorized.\n",
    "\n",
    "* Mini-Batch-gradient descent:\n",
    "    - In this data is divided into mini batches.\n",
    "    - so, it gives the advantages of both SGD and Batch Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q14. What is learning rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A14.\n",
    "*  Learning rate $\\alpha$ is an hyper parameter used to control the rate at which the algorithm updates the paramerter estimates.\n",
    "* Learning rate decides the iteration length at which gredient descents to minimal point.\n",
    "* If the learning rate is high the algorithm may jump the optimal point.\n",
    "* If the learning rate is too small algorith takes lot of time to cionverge the minimal point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q15. Define the following terms. Explain their importance in the data analysis.\n",
    "    - $R^2$\n",
    "    - Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A15.\n",
    "* $R^2$ : It gives the proportion of variation in the target variable.\n",
    "  - $R^2$ is given by: $\\frac{(TSS - RSS)}{TSS}$\n",
    "  - The Total sum of squares is given by: $TSS = {\\sum({y_{i} - \\bar{y}}})^2$\n",
    "  - The Residual sum of squares is given by: $RSS = {\\sum({y_{i} - \\hat{y}}})^2$\n",
    "* $Adj. R^2$ : \n",
    "  - $R^2$ never decreases on the addition of any new feature to the dataset.\n",
    "  - so adjusted R square is introduced to overcome that issue.\n",
    "  - The Adjusted R-squared takes into account the number of independent variables used for predicting the target variable. \n",
    "  - so, we can determine whether adding new variables to the model actually increases the model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q16. Explain One-Hot Encoding and Label Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A16.\n",
    "* One hot encoding:\n",
    "   - Method to convert categorical feature to numerical feature.\n",
    "   - It is applied for nominal data like gender.\n",
    "   - It takes unique values in the feature and create a seperate feature for that unique value where all the indices with that value in the original feature are marked as 1 and rest as 0.\n",
    "\n",
    "* Label Encoding:\n",
    "   - This is also a method to convert categorical data into numerical.\n",
    "   - It assigns a unique number to each class of the data and all the data is represented into a numeric vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q17. What are the assumption on Naive Bayes algorithm in classification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A17.\n",
    "- All the features are independent.\n",
    "- The likelihood probabilities follows Gaussian distribution.\n",
    "- The prior probabilities for each class is either uniform or known beforehand empirically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q18. What is the difference between classification and regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A18. \n",
    "- The key differences are:\n",
    "   - Classification is used to predict discrete data. \n",
    "   - for example classifing cats and dogs.\n",
    "   - Regression is used to predict the continous data.\n",
    "   - example: House prices in a particular city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q19. How to ensure that the model is not overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A19.\n",
    "- Cross Validation\n",
    "- Regularization\n",
    "- Early stopping\n",
    "- Feature selection\n",
    "- Dimensiopnality reduction\n",
    "- Data Augmentation or feeding more data to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q20. List the main advantage of Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A20.\n",
    "- If its assumptions holds true then it can outperform other techniques.\n",
    "- It computes faster than other data\n",
    "- It works well even with less training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q21. What you shoud do when your model is suffereing from:\n",
    "    - Low bias and high variance?\n",
    "    - High bias and low variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A21.\n",
    "- High Bias and Low Variance - \n",
    "    - Regularization\n",
    "    - Add more training data\n",
    "- Low Bias and High Variance - \n",
    "    - increasing the complexity of the model to better fit the data\n",
    "    - decreasing the regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q22. What is the 'Naive' in the Naive Bayes Classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A22.\n",
    "* The features are independent.\n",
    "* The likelihood distribution is fixed as Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q23. What is bias-variance tradeoff in Machine Learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A23. \n",
    "* If the model has few params and simple, bias occurs.\n",
    "* If the model has too many params and complex, variance increases.\n",
    "* if we try to decrease bias variance will increase and vice versa this the trade off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q24. Explain different trade-offs in Machine Learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A24.\n",
    "Different trade-offs in ML:\n",
    "- Bias- Variance Tradeoff\n",
    "- Interpretability and Accuracy tradeoff\n",
    "- Precision Recall Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q25. What is cross-validation and how it is useful in traing ML models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation is useful when model tries to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7758e92e9a61d7a3490898707f7eeb937c85e9d1e8d4e877cc6c187218f226d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
